{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6188e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2010-2018 by Haibao Tang et al. All rights reserved.\n",
    "#\n",
    "# This code is part of the goatools distribution and goverend by its\n",
    "# license. Please see the LICENSE file included with goatools.\n",
    "\n",
    "\n",
    "\"\"\"Read and store Gene Ontology's obo file.\"\"\"\n",
    "# -*- coding: UTF-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from goatools.godag.obo_optional_attributes import OboOptionalAttrs\n",
    "from goatools.godag.typedef import TypeDef\n",
    "from goatools.godag.typedef import add_to_typedef\n",
    "\n",
    "GraphEngines = (\"pygraphviz\", \"pydot\")\n",
    "\n",
    "__copyright__ = \"Copyright (C) 2010-2018, H Tang et al., All rights reserved.\"\n",
    "__author__ = \"various\"\n",
    "\n",
    "\n",
    "#pylint: disable=too-few-public-methods\n",
    "class OBOReader(object):\n",
    "    \"\"\"Read goatools.org's obo file. Load into this iterable class.\n",
    "\n",
    "        Download obo from: http://geneontology.org/ontology/go-basic.obo\n",
    "\n",
    "        >>> reader = OBOReader()\n",
    "        >>> for rec in reader:\n",
    "                print(rec)\n",
    "    \"\"\"\n",
    "\n",
    "    # Scalar attributes for Typedefs:\n",
    "    #                    'is_class_level', 'is_metadata_tag',\n",
    "    #                    'is_transitive', 'transitive_over'])\n",
    "\n",
    "    def __init__(self, obo_file=\"go-basic.obo\", optional_attrs=None):\n",
    "        \"\"\"Read obo file. Load dictionary.\"\"\"\n",
    "        self.optobj = self._init_optional_attrs(optional_attrs)  # OboOptionalAttrs or None\n",
    "        self.format_version = None # e.g., \"1.2\" of \"format-version:\" line\n",
    "        self.data_version = None # e.g., \"releases/2016-07-07\" from \"data-version:\" line\n",
    "        self.typedefs = {}\n",
    "\n",
    "        # True if obo file exists or if a link to an obo file exists.\n",
    "        if os.path.isfile(obo_file):\n",
    "            self.obo_file = obo_file\n",
    "            # GOTerm attributes that are necessary for any operations:\n",
    "        else:\n",
    "            raise Exception(\"COULD NOT READ({OBO})\\n\"\n",
    "                            \"download obo file first\\n \"\n",
    "                            \"[http://geneontology.org/ontology/\"\n",
    "                            \"go-basic.obo]\".format(OBO=obo_file))\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Return one GO Term record at a time from an obo file.\"\"\"\n",
    "        # Wait to open file until needed. Automatically close file when done.\n",
    "        with open(self.obo_file) as fstream:\n",
    "            rec_curr = None # Stores current GO Term\n",
    "            typedef_curr = None  # Stores current typedef\n",
    "            for line in fstream:\n",
    "                # obo lines start with any of: [Term], [Typedef], /^\\S+:/, or /^\\s*/\n",
    "                if self.data_version is None:\n",
    "                    self._init_obo_version(line)\n",
    "                if rec_curr is None and line[0:6].lower() == \"[term]\":\n",
    "                    rec_curr = GOTerm()\n",
    "                    if self.optobj:\n",
    "                        self.optobj.init_datamembers(rec_curr)\n",
    "                elif typedef_curr is None and line[0:9].lower() == \"[typedef]\":\n",
    "                    typedef_curr = TypeDef()\n",
    "                elif rec_curr is not None or typedef_curr is not None:\n",
    "                    line = line.rstrip()  # chomp\n",
    "                    if line:\n",
    "                        self._add_to_obj(rec_curr, typedef_curr, line)\n",
    "                    else:\n",
    "                        if rec_curr is not None:\n",
    "                            yield rec_curr\n",
    "                            rec_curr = None\n",
    "                        elif typedef_curr is not None:\n",
    "                            # Save typedef.\n",
    "                            self.typedefs[typedef_curr.item_id] = typedef_curr\n",
    "                            typedef_curr = None\n",
    "            # Return last record, if necessary\n",
    "            if rec_curr is not None:\n",
    "                yield rec_curr\n",
    "\n",
    "    def _add_to_obj(self, rec_curr, typedef_curr, line):\n",
    "        \"\"\"Add information on line to GOTerm or Typedef.\"\"\"\n",
    "        if rec_curr is not None:\n",
    "            self._add_to_ref(rec_curr, line)\n",
    "        else:\n",
    "            add_to_typedef(typedef_curr, line)\n",
    "\n",
    "    def _init_obo_version(self, line):\n",
    "        \"\"\"Save obo version and release.\"\"\"\n",
    "        if line[0:14] == \"format-version\":\n",
    "            self.format_version = line[16:-1]\n",
    "        if line[0:12] == \"data-version\":\n",
    "            self.data_version = line[14:-1]\n",
    "\n",
    "    def _add_to_ref(self, rec_curr, line):        \n",
    "        \n",
    "        \"\"\"Add new fields to the current reference.\"\"\"\n",
    "        # Examples of record lines containing ':' include:\n",
    "        #   id: GO:0000002\n",
    "        #   name: mitochondrial genome maintenance\n",
    "        #   namespace: biological_process\n",
    "        #   def: \"The maintenance of ...\n",
    "        #   is_a: GO:0007005 ! mitochondrion organization\n",
    "        l = len('MONDO:')\n",
    "        if line[:4] == \"id: \":\n",
    "            assert not rec_curr.item_id\n",
    "            item_id = line[4+l:]\n",
    "            rec_curr.item_id = item_id\n",
    "            rec_curr.id = item_id\n",
    "        elif line[:8] == \"alt_id: \":\n",
    "            rec_curr.alt_ids.add(line[8+l:])\n",
    "        elif line[:6] == \"name: \":\n",
    "            assert not rec_curr.name\n",
    "            rec_curr.name = line[6:]\n",
    "        elif line[:5] == \"def: \": \n",
    "            rec_curr.definition = line[5:]\n",
    "        #elif line[:11] == \"namespace: \":\n",
    "        #    assert not rec_curr.namespace\n",
    "        #    rec_curr.namespace = line[11:]\n",
    "        elif line[:6] == \"is_a: \":\n",
    "            rec_curr._parents.add(line[6+l:].split()[0])\n",
    "        elif line[:8] == \"subset: \": \n",
    "            rec_curr.subsets.add(line[8:].split()[0])\n",
    "        elif line[:6] =='xref: ': \n",
    "            if line[:10] != 'xref: url:':\n",
    "                rec_curr.xrefs.add(line[6:].split()[0])\n",
    "        elif 'closeMatch' in line: \n",
    "            if 'umls' in line: \n",
    "                ref = 'UMLS:'+line.split('/')[-1]\n",
    "            elif 'snomedct' in line: \n",
    "                ref = 'SCTID:'+line.split('/')[-1]\n",
    "            elif 'mesh' in line: \n",
    "                ref = 'MESH:'+line.split('/')[-1]\n",
    "            elif 'medgen' in line: \n",
    "                ref = 'MEDGEN:'+line.split('/')[-1]\n",
    "            elif 'meddra' in line: \n",
    "                ref = 'MedDRA:'+line.split('/')[-1]\n",
    "            elif 'omim' in line: \n",
    "                ref = 'OMIM:'+line.split('/')[-1]\n",
    "            elif 'DOID' in line: \n",
    "                ref = 'DOID:'+line.split(':')[-1]\n",
    "            elif 'NCIT' in line: \n",
    "                ref = 'NCIT:'+line.split(':')[-1]\n",
    "            elif 'Orphanet' in line: \n",
    "                ref = 'Orphanet:'+line.split(':')[-1]\n",
    "            else:\n",
    "                print('closeMatch not added for:', line)\n",
    "                ref=None\n",
    "            rec_curr.xrefs.add(ref)\n",
    "        #elif line[:9] =='synonym: ': \n",
    "       #     rel, name = line[9:].split()[-2:]\n",
    "       #     name = name[1:-1]\n",
    "       #     rec_curr.synonyms.add((name,rel))            \n",
    "        elif line[:13] == \"is_obsolete: \" and line[13:] == \"true\":\n",
    "            rec_curr.is_obsolete = True\n",
    "        elif line[:13] == \"replaced_by: \": \n",
    "            rec_curr.replaced_by = line[13+l:]\n",
    "        elif self.optobj and ':' in line:\n",
    "            self.optobj.update_rec(rec_curr, line)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def _init_optional_attrs(optional_attrs):\n",
    "        \"\"\"Create OboOptionalAttrs or return None.\"\"\"\n",
    "        if optional_attrs is None:\n",
    "            return None\n",
    "        opts = OboOptionalAttrs.get_optional_attrs(optional_attrs, OboOptionalAttrs.optional_exp)\n",
    "        if opts:\n",
    "            return OboOptionalAttrs(opts)\n",
    "\n",
    "\n",
    "class GOTerm(object):\n",
    "    \"\"\"\n",
    "    GO term, actually contain a lot more properties than interfaced here\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.id = \"\"                # GO:NNNNNNN  **DEPRECATED** RESERVED NAME IN PYTHON\n",
    "        self.item_id = \"\"           # GO:NNNNNNN (will replace deprecated \"id\")\n",
    "        self.name = \"\"              # description\n",
    "        #self.namespace = \"\"         # BP, CC, MF\n",
    "        self._parents = set()       # is_a basestring of parents\n",
    "        self.alt_ids = set()        # alternative identifiers\n",
    "        self.subsets = set()\n",
    "        #self.synonyms = set()\n",
    "        self.xrefs = set()\n",
    "        self.is_obsolete = False\n",
    "        self.replaced_by = None\n",
    "        self.definition = \"\"\n",
    "        \n",
    "        # not used\n",
    "        #self.parents = set()        # parent records\n",
    "        #self.children = set()       # children records\n",
    "        #self.level = None           # shortest distance from root node\n",
    "        #self.depth = None           # longest distance from root node\n",
    "\n",
    "    def __str__(self):\n",
    "        ret = ['{GO}\\t'.format(GO=self.item_id)]\n",
    "        if self.level is not None:\n",
    "            ret.append('level-{L:>02}\\t'.format(L=self.level))\n",
    "        if self.depth is not None:\n",
    "            ret.append('depth-{D:>02}\\t'.format(D=self.depth))\n",
    "        ret.append('{NAME} [{NS}]'.format(NAME=self.name, NS=self.namespace))\n",
    "        if self.is_obsolete:\n",
    "            ret.append('obsolete')\n",
    "        return ''.join(ret)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Print GO ID and all attributes in GOTerm class.\"\"\"\n",
    "        ret = [\"GOTerm('{ID}'):\".format(ID=self.item_id)]\n",
    "        for key, val in self.__dict__.items():\n",
    "            if isinstance(val, int) or isinstance(val, str):\n",
    "                ret.append(\"{K}:{V}\".format(K=key, V=val))\n",
    "            elif val is not None:\n",
    "                ret.append(\"{K}: {V} items\".format(K=key, V=len(val)))\n",
    "                if len(val) < 10:\n",
    "                    if not isinstance(val, dict):\n",
    "                        for elem in val:\n",
    "                            ret.append(\"  {ELEM}\".format(ELEM=elem))\n",
    "                    else:\n",
    "                        for (typedef, terms) in val.items():\n",
    "                            ret.append(\"  {TYPEDEF}: {NTERMS} items\"\n",
    "                                       .format(TYPEDEF=typedef,\n",
    "                                               NTERMS=len(terms)))\n",
    "                            for term in terms:\n",
    "                                ret.append(\"    {TERM}\".format(TERM=term))\n",
    "            else:\n",
    "                ret.append(\"{K}: None\".format(K=key))\n",
    "        return \"\\n  \".join(ret)\n",
    "\n",
    "    def has_parent(self, term):\n",
    "        \"\"\"Return True if this GO object has a parent GO ID.\"\"\"\n",
    "        for parent in self.parents:\n",
    "            if parent.item_id == term or parent.has_parent(term):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def has_child(self, term):\n",
    "        \"\"\"Return True if this GO object has a child GO ID.\"\"\"\n",
    "        for parent in self.children:\n",
    "            if parent.item_id == term or parent.has_child(term):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_all_parents(self):\n",
    "        \"\"\"Return all parent GO IDs.\"\"\"\n",
    "        all_parents = set()\n",
    "        for parent in self.parents:\n",
    "            all_parents.add(parent.item_id)\n",
    "            all_parents |= parent.get_all_parents()\n",
    "        return all_parents\n",
    "\n",
    "    def get_all_upper(self):\n",
    "        \"\"\"Return all parent GO IDs through both 'is_a' and all relationships.\"\"\"\n",
    "        all_upper = set()\n",
    "        for upper in self.get_goterms_upper():\n",
    "            all_upper.add(upper.item_id)\n",
    "            all_upper |= upper.get_all_upper()\n",
    "        return all_upper\n",
    "\n",
    "    def get_all_children(self):\n",
    "        \"\"\"Return all children GO IDs.\"\"\"\n",
    "        all_children = set()\n",
    "        for parent in self.children:\n",
    "            all_children.add(parent.item_id)\n",
    "            all_children |= parent.get_all_children()\n",
    "        return all_children\n",
    "\n",
    "    def get_all_lower(self):\n",
    "        \"\"\"Return all parent GO IDs through both reverse 'is_a' and all relationships.\"\"\"\n",
    "        all_lower = set()\n",
    "        for lower in self.get_goterms_lower():\n",
    "            all_lower.add(lower.item_id)\n",
    "            all_lower |= lower.get_all_lower()\n",
    "        return all_lower\n",
    "\n",
    "    def get_all_parent_edges(self):\n",
    "        \"\"\"Return tuples for all parent GO IDs, containing current GO ID and parent GO ID.\"\"\"\n",
    "        all_parent_edges = set()\n",
    "        for parent in self.parents:\n",
    "            all_parent_edges.add((self.item_id, parent.item_id))\n",
    "            all_parent_edges |= parent.get_all_parent_edges()\n",
    "        return all_parent_edges\n",
    "\n",
    "    def get_all_child_edges(self):\n",
    "        \"\"\"Return tuples for all child GO IDs, containing current GO ID and child GO ID.\"\"\"\n",
    "        all_child_edges = set()\n",
    "        for parent in self.children:\n",
    "            all_child_edges.add((parent.item_id, self.item_id))\n",
    "            all_child_edges |= parent.get_all_child_edges()\n",
    "        return all_child_edges\n",
    "\n",
    "    def get_goterms_upper(self):\n",
    "        \"\"\"Returns a set containing parents and all relationship GO Terms.\"\"\"\n",
    "        # Requires GODag is created with 'relationship' in optional_attrs argument\n",
    "        # pylint: disable=no-member\n",
    "        return set.union(self.parents, *self.relationship.values())\n",
    "\n",
    "    def get_goterms_upper_rels(self, relationship_set):\n",
    "        \"\"\"Returns a set containing parents and specified relationship GO Terms.\"\"\"\n",
    "        # Requires GODag is created with 'relationship' in optional_attrs argument\n",
    "        # pylint: disable=no-member\n",
    "        terms = [term_set for r, term_set in self.relationship.items() if r in relationship_set]\n",
    "        return set.union(self.parents, *terms)\n",
    "\n",
    "    def get_goterms_lower(self):\n",
    "        \"\"\"Returns a set containing children and all reverse-relationship GO Terms.\"\"\"\n",
    "        # Requires GODag is created with 'relationship' in optional_attrs argument\n",
    "        # pylint: disable=no-member\n",
    "        return set.union(self.children, *self.relationship_rev.values())\n",
    "\n",
    "    def get_goterms_lower_rels(self, relationship_set):\n",
    "        \"\"\"Returns a set containing children and specified reverse-relationship GO Terms.\"\"\"\n",
    "        # Requires GODag is created with 'relationship' in optional_attrs argument\n",
    "        # pylint: disable=no-member\n",
    "        terms = [term_set for r, term_set in self.relationship_rev.items() if r in relationship_set]\n",
    "        return set.union(self.children, *terms)\n",
    "\n",
    "\n",
    "class GODag(dict):\n",
    "    \"\"\"Holds the GO DAG as a dict.\"\"\"\n",
    "\n",
    "    def __init__(self, obo_file=\"go-basic.obo\", optional_attrs=None, load_obsolete=False, prt=sys.stdout):\n",
    "        super(GODag, self).__init__()\n",
    "        self.version, self.data_version = self.load_obo_file(obo_file, optional_attrs, load_obsolete, prt)\n",
    "\n",
    "    def load_obo_file(self, obo_file, optional_attrs, load_obsolete, prt):\n",
    "        \"\"\"Read obo file. Store results.\"\"\"\n",
    "        reader = OBOReader(obo_file, optional_attrs)\n",
    "\n",
    "        # Save alt_ids and their corresponding main GO ID. Add to GODag after populating GO Terms\n",
    "        alt2rec = {}\n",
    "        for rec in reader:\n",
    "            # Save record if:\n",
    "            #   1) Argument load_obsolete is True OR\n",
    "            #   2) Argument load_obsolete is False and the GO term is \"live\" (not obsolete)\n",
    "            if load_obsolete or not rec.is_obsolete:\n",
    "                self[rec.item_id] = rec\n",
    "                for alt in rec.alt_ids:\n",
    "                    alt2rec[alt] = rec\n",
    "\n",
    "        # Save the typedefs and parsed optional_attrs\n",
    "        # self.optobj = reader.optobj\n",
    "        self.typedefs = reader.typedefs\n",
    "\n",
    "        self._populate_terms(reader.optobj)\n",
    "        self._set_level_depth(reader.optobj)\n",
    "\n",
    "        # Add alt_ids to go2obj\n",
    "        for goid_alt, rec in alt2rec.items():\n",
    "            self[goid_alt] = rec\n",
    "        desc = self._str_desc(reader)\n",
    "        if prt:\n",
    "            prt.write(\"{DESC}\\n\".format(DESC=desc))\n",
    "        return desc, reader.data_version\n",
    "\n",
    "    def _str_desc(self, reader):\n",
    "        \"\"\"String containing information about the current GO DAG.\"\"\"\n",
    "        data_version = reader.data_version\n",
    "        if data_version is not None:\n",
    "            data_version = data_version.replace(\"releases/\", \"\")\n",
    "        desc = \"{OBO}: fmt({FMT}) rel({REL}) {N:,} GO Terms\".format(\n",
    "            OBO=reader.obo_file, FMT=reader.format_version,\n",
    "            REL=data_version, N=len(self))\n",
    "        if reader.optobj:\n",
    "            desc = \"{D}; optional_attrs({A})\".format(D=desc, A=\" \".join(sorted(reader.optobj.optional_attrs)))\n",
    "        return desc\n",
    "\n",
    "\n",
    "    def _populate_terms(self, optobj):\n",
    "        \"\"\"Convert GO IDs to GO Term record objects. Populate children.\"\"\"\n",
    "        has_relationship = optobj is not None and 'relationship' in optobj.optional_attrs\n",
    "        # Make parents and relationships references to the actual GO terms.\n",
    "        for rec in self.values():\n",
    "            # Given parent GO IDs, set parent GO Term objects\n",
    "            rec.parents = set([self[goid] for goid in rec._parents])\n",
    "\n",
    "            # For each parent GO Term object, add it's child GO Term to the children data member\n",
    "            for parent_rec in rec.parents:\n",
    "                parent_rec.children.add(rec)\n",
    "\n",
    "            if has_relationship:\n",
    "                self._populate_relationships(rec)\n",
    "\n",
    "    def _populate_relationships(self, rec_curr):\n",
    "        \"\"\"Convert GO IDs in relationships to GO Term record objects. Populate children.\"\"\"\n",
    "        for relationship_type, goids in rec_curr.relationship.items():\n",
    "            parent_recs = set([self[goid] for goid in goids])\n",
    "            rec_curr.relationship[relationship_type] = parent_recs\n",
    "            for parent_rec in parent_recs:\n",
    "                if relationship_type not in parent_rec.relationship_rev:\n",
    "                    parent_rec.relationship_rev[relationship_type] = set([rec_curr])\n",
    "                else:\n",
    "                    parent_rec.relationship_rev[relationship_type].add(rec_curr)\n",
    "\n",
    "    def _set_level_depth(self, optobj):\n",
    "        \"\"\"Set level, depth and add inverted relationships.\"\"\"\n",
    "        has_relationship = optobj is not None and 'relationship' in optobj.optional_attrs\n",
    "\n",
    "        def _init_level(rec):\n",
    "            if rec.level is None:\n",
    "                if rec.parents:\n",
    "                    rec.level = min(_init_level(rec) for rec in rec.parents) + 1\n",
    "                else:\n",
    "                    rec.level = 0\n",
    "            return rec.level\n",
    "\n",
    "        def _init_depth(rec):\n",
    "            if rec.depth is None:\n",
    "                if rec.parents:\n",
    "                    rec.depth = max(_init_depth(rec) for rec in rec.parents) + 1\n",
    "                else:\n",
    "                    rec.depth = 0\n",
    "            return rec.depth\n",
    "\n",
    "        def _init_reldepth(rec):\n",
    "            if not hasattr(rec, 'reldepth'):\n",
    "                up_terms = rec.get_goterms_upper()\n",
    "                if up_terms:\n",
    "                    rec.reldepth = max(_init_reldepth(rec) for rec in up_terms) + 1\n",
    "                else:\n",
    "                    rec.reldepth = 0\n",
    "            return rec.reldepth\n",
    "\n",
    "        for rec in self.values():\n",
    "\n",
    "            # Add invert relationships\n",
    "            if has_relationship:\n",
    "                if rec.depth is None:\n",
    "                    _init_reldepth(rec)\n",
    "\n",
    "                # print(\"BBBBBBBBBBB1\", rec.item_id, rec.relationship)\n",
    "                #for (typedef, terms) in rec.relationship.items():\n",
    "                #    invert_typedef = self.typedefs[typedef].inverse_of\n",
    "                #    # print(\"BBBBBBBBBBB2 {} ({}) ({}) ({})\".format(\n",
    "                #    #    rec.item_id, rec.relationship, typedef, invert_typedef))\n",
    "                #    if invert_typedef:\n",
    "                #        # Add inverted relationship\n",
    "                #        for term in terms:\n",
    "                #            if not hasattr(term, 'relationship'):\n",
    "                #                term.relationship = defaultdict(set)\n",
    "                #            term.relationship[invert_typedef].add(rec)\n",
    "                # print(\"BBBBBBBBBBB3\", rec.item_id, rec.relationship)\n",
    "\n",
    "            if rec.level is None:\n",
    "                _init_level(rec)\n",
    "\n",
    "            if rec.depth is None:\n",
    "                _init_depth(rec)\n",
    "\n",
    "    def write_dag(self, out=sys.stdout):\n",
    "        \"\"\"Write info for all GO Terms in obo file, sorted numerically.\"\"\"\n",
    "        for rec in sorted(self.values()):\n",
    "            print(rec, file=out)\n",
    "\n",
    "####    def write_hier_all(self, out=sys.stdout,\n",
    "####                       len_dash=1, max_depth=None, num_child=None, short_prt=False):\n",
    "####        \"\"\"Write hierarchy for all GO Terms in obo file.\"\"\"\n",
    "####        # Print: [biological_process, molecular_function, and cellular_component]\n",
    "####        for go_id in ['GO:0008150', 'GO:0003674', 'GO:0005575']:\n",
    "####            self.write_hier(go_id, out, len_dash, max_depth, num_child, short_prt, None)\n",
    "####\n",
    "####    def write_hier(self, go_id, out=sys.stdout,\n",
    "####                   len_dash=1, max_depth=None, num_child=None, short_prt=False,\n",
    "####                   include_only=None, go_marks=None):\n",
    "####        \"\"\"Write hierarchy for a GO Term.\"\"\"\n",
    "####        gos_printed = set()\n",
    "####        self[go_id].write_hier_rec(gos_printed, out, len_dash, max_depth, num_child,\n",
    "####                                   short_prt, include_only, go_marks)\n",
    "\n",
    "    @staticmethod\n",
    "    def id2int(go_id):\n",
    "        \"\"\"Given a GO ID, return the int value.\"\"\"\n",
    "        return int(go_id.replace(\"GO:\", \"\", 1))\n",
    "\n",
    "    def query_term(self, term, verbose=False):\n",
    "        \"\"\"Given a GO ID, return GO object.\"\"\"\n",
    "        if term not in self:\n",
    "            sys.stderr.write(\"Term %s not found!\\n\" % term)\n",
    "            return\n",
    "\n",
    "        rec = self[term]\n",
    "        if verbose:\n",
    "            print(rec)\n",
    "            sys.stderr.write(\"all parents: {}\\n\".format(\n",
    "                repr(rec.get_all_parents())))\n",
    "            sys.stderr.write(\"all children: {}\\n\".format(\n",
    "                repr(rec.get_all_children())))\n",
    "        return rec\n",
    "\n",
    "    def paths_to_top(self, term):\n",
    "        \"\"\" Returns all possible paths to the root node\n",
    "\n",
    "            Each path includes the term given. The order of the path is\n",
    "            top -> bottom, i.e. it starts with the root and ends with the\n",
    "            given term (inclusively).\n",
    "\n",
    "            Parameters:\n",
    "            -----------\n",
    "            - term:\n",
    "                the ID of the GO term, where the paths begin (i.e. the\n",
    "                accession 'GO:0003682')\n",
    "\n",
    "            Returns:\n",
    "            --------\n",
    "            - a list of lists of GO Terms\n",
    "        \"\"\"\n",
    "        # error handling consistent with original authors\n",
    "        if term not in self:\n",
    "            sys.stderr.write(\"Term %s not found!\\n\" % term)\n",
    "            return\n",
    "\n",
    "        def _paths_to_top_recursive(rec):\n",
    "            if rec.level == 0:\n",
    "                return [[rec]]\n",
    "            paths = []\n",
    "            for parent in rec.parents:\n",
    "                top_paths = _paths_to_top_recursive(parent)\n",
    "                for top_path in top_paths:\n",
    "                    top_path.append(rec)\n",
    "                    paths.append(top_path)\n",
    "            return paths\n",
    "\n",
    "        go_term = self[term]\n",
    "        return _paths_to_top_recursive(go_term)\n",
    "\n",
    "    def label_wrap(self, label):\n",
    "        \"\"\"Label text for plot.\"\"\"\n",
    "        wrapped_label = r\"%s\\n%s\" % (label,\n",
    "                                     self[label].name.replace(\",\", r\"\\n\"))\n",
    "        return wrapped_label\n",
    "\n",
    "    def make_graph_pydot(self, recs, nodecolor,\n",
    "                         edgecolor, dpi,\n",
    "                         draw_parents=True, draw_children=True):\n",
    "        \"\"\"draw AMIGO style network, lineage containing one query record.\"\"\"\n",
    "        import pydot\n",
    "        grph = pydot.Dot(graph_type='digraph', dpi=\"{}\".format(dpi)) # Directed Graph\n",
    "        edgeset = set()\n",
    "        usr_ids = [rec.item_id for rec in recs]\n",
    "        for rec in recs:\n",
    "            if draw_parents:\n",
    "                edgeset.update(rec.get_all_parent_edges())\n",
    "            if draw_children:\n",
    "                edgeset.update(rec.get_all_child_edges())\n",
    "\n",
    "        rec_id_set = set([rec_id for endpts in edgeset for rec_id in endpts])\n",
    "        nodes = {str(ID):pydot.Node(\n",
    "            self.label_wrap(ID).replace(\"GO:\", \"\"),  # Node name\n",
    "            shape=\"box\",\n",
    "            style=\"rounded, filled\",\n",
    "            # Highlight query terms in plum:\n",
    "            fillcolor=\"beige\" if ID not in usr_ids else \"plum\",\n",
    "            color=nodecolor)\n",
    "                 for ID in rec_id_set}\n",
    "\n",
    "        # add nodes explicitly via add_node\n",
    "        for rec_id, node in nodes.items():\n",
    "            grph.add_node(node)\n",
    "\n",
    "        for src, target in edgeset:\n",
    "            # default layout in graphviz is top->bottom, so we invert\n",
    "            # the direction and plot using dir=\"back\"\n",
    "            grph.add_edge(pydot.Edge(nodes[target], nodes[src],\n",
    "                                     shape=\"normal\",\n",
    "                                     color=edgecolor,\n",
    "                                     label=\"is_a\",\n",
    "                                     dir=\"back\"))\n",
    "\n",
    "        return grph\n",
    "\n",
    "    def make_graph_pygraphviz(self, recs, nodecolor,\n",
    "                              edgecolor, dpi,\n",
    "                              draw_parents=True, draw_children=True):\n",
    "        \"\"\"Draw AMIGO style network, lineage containing one query record.\"\"\"\n",
    "        import pygraphviz as pgv\n",
    "\n",
    "        grph = pgv.AGraph(name=\"GO tree\")\n",
    "\n",
    "        edgeset = set()\n",
    "        for rec in recs:\n",
    "            if draw_parents:\n",
    "                edgeset.update(rec.get_all_parent_edges())\n",
    "            if draw_children:\n",
    "                edgeset.update(rec.get_all_child_edges())\n",
    "\n",
    "        edgeset = [(self.label_wrap(a), self.label_wrap(b))\n",
    "                   for (a, b) in edgeset]\n",
    "\n",
    "        # add nodes explicitly via add_node\n",
    "        # adding nodes implicitly via add_edge misses nodes\n",
    "        # without at least one edge\n",
    "        for rec in recs:\n",
    "            grph.add_node(self.label_wrap(rec.item_id))\n",
    "\n",
    "        for src, target in edgeset:\n",
    "            # default layout in graphviz is top->bottom, so we invert\n",
    "            # the direction and plot using dir=\"back\"\n",
    "            grph.add_edge(target, src)\n",
    "\n",
    "        grph.graph_attr.update(dpi=\"%d\" % dpi)\n",
    "        grph.node_attr.update(shape=\"box\", style=\"rounded,filled\",\n",
    "                              fillcolor=\"beige\", color=nodecolor)\n",
    "        grph.edge_attr.update(shape=\"normal\", color=edgecolor,\n",
    "                              dir=\"back\", label=\"is_a\")\n",
    "        # highlight the query terms\n",
    "        for rec in recs:\n",
    "            try:\n",
    "                node = grph.get_node(self.label_wrap(rec.item_id))\n",
    "                node.attr.update(fillcolor=\"plum\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        return grph\n",
    "\n",
    "    def draw_lineage(self, recs, nodecolor=\"mediumseagreen\",\n",
    "                     edgecolor=\"lightslateblue\", dpi=96,\n",
    "                     lineage_img=\"GO_lineage.png\", engine=\"pygraphviz\",\n",
    "                     gml=False, draw_parents=True, draw_children=True):\n",
    "        \"\"\"Draw GO DAG subplot.\"\"\"\n",
    "        assert engine in GraphEngines\n",
    "        grph = None\n",
    "        if engine == \"pygraphviz\":\n",
    "            grph = self.make_graph_pygraphviz(recs, nodecolor, edgecolor, dpi,\n",
    "                                              draw_parents=draw_parents,\n",
    "                                              draw_children=draw_children)\n",
    "        else:\n",
    "            grph = self.make_graph_pydot(recs, nodecolor, edgecolor, dpi,\n",
    "                                         draw_parents=draw_parents, draw_children=draw_children)\n",
    "\n",
    "        if gml:\n",
    "            import networkx as nx  # use networkx to do the conversion\n",
    "            gmlbase = lineage_img.rsplit(\".\", 1)[0]\n",
    "            obj = nx.from_agraph(grph) if engine == \"pygraphviz\" else nx.from_pydot(grph)\n",
    "\n",
    "            del obj.graph['node']\n",
    "            del obj.graph['edge']\n",
    "            gmlfile = gmlbase + \".gml\"\n",
    "            nx.write_gml(self.label_wrap, gmlfile)\n",
    "            sys.stderr.write(\"GML graph written to {0}\\n\".format(gmlfile))\n",
    "\n",
    "        sys.stderr.write((\"lineage info for terms %s written to %s\\n\" %\n",
    "                          ([rec.item_id for rec in recs], lineage_img)))\n",
    "\n",
    "        if engine == \"pygraphviz\":\n",
    "            grph.draw(lineage_img, prog=\"dot\")\n",
    "        else:\n",
    "            grph.write_png(lineage_img)\n",
    "\n",
    "    def update_association(self, association):\n",
    "        \"\"\"Add the GO parents of a gene's associated GO IDs to the gene's association.\"\"\"\n",
    "        bad_goids = set()\n",
    "        # Loop through all sets of GO IDs for all genes\n",
    "        for goids in association.values():\n",
    "            parents = set()\n",
    "            # Iterate thru each GO ID in the current gene's association\n",
    "            for goid in goids:\n",
    "                try:\n",
    "                    parents.update(self[goid].get_all_parents())\n",
    "                except:\n",
    "                    bad_goids.add(goid.strip())\n",
    "            # Add the GO parents of all GO IDs in the current gene's association\n",
    "            goids.update(parents)\n",
    "        if bad_goids:\n",
    "            sys.stdout.write(\"{N} GO IDs in assc. are not found in the GO-DAG: {GOs}\\n\".format(\n",
    "                N=len(bad_goids), GOs=\" \".join(bad_goids)))\n",
    "\n",
    "# Copyright (C) 2010-2018, H Tang et al., All rights reserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062e6e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24395 total terms\n",
      "22159 not obsolete\n",
      "\"is_a\" relationships between mondo terms\n",
      "cross references from mondo to other ontologies\n",
      "references to the following ontologies are available:\n",
      "['COHD' 'CSP' 'DC' 'DERMO' 'DOID' 'EFO' 'GARD' 'GTR' 'HGNC' 'HP' 'ICD10'\n",
      " 'ICD10CM' 'ICD11' 'ICD9' 'ICD9CM' 'ICDO' 'IDO' 'KEGG' 'LOINC' 'MEDDRA'\n",
      " 'MEDGEN' 'MESH' 'MFOMD' 'MONDO' 'MP' 'MTH' 'MedDRA' 'NCIT' 'NDFRT'\n",
      " 'NIFSTD' 'OBI' 'OGMS' 'OMIM' 'OMIMPS' 'OMOP' 'ONCOTREE' 'ORDO' 'Orphanet'\n",
      " 'PATO' 'PMID' 'Reactome' 'SCDO' 'SCTID' 'SCTID_2010_1_31' 'UMLS'\n",
      " 'UMLS_CUI' 'Wikidata' 'Wikipedia' 'http' 'https']\n",
      "references from mondo to mondo indicate equivalence/synonyms\n",
      "groupings of mondo terms\n",
      "available subsets by count:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from mondo_obo_parser import OBOReader\n",
    "\n",
    "pth = \"mondo.obo\"\n",
    "data = [*iter(OBOReader(pth))]\n",
    "mondo_terms = pd.DataFrame([{'id':x.item_id, \n",
    "                             'name':x.name, \n",
    "                             'definition':x.definition,\n",
    "                             'is_obsolete':x.is_obsolete,\n",
    "                             'replacement_id': x.replaced_by} for x in data])\n",
    "print(mondo_terms.shape[0], \"total terms\")\n",
    "print(mondo_terms.query('is_obsolete==False').shape[0], 'not obsolete')\n",
    "\n",
    "print('\"is_a\" relationships between mondo terms')\n",
    "mondo_parents = []\n",
    "for x in data: \n",
    "    if x._parents: \n",
    "        for parent in x._parents: \n",
    "            mondo_parents.append({'parent':parent, 'child':x.item_id})           \n",
    "mondo_parents = pd.DataFrame(mondo_parents).drop_duplicates()\n",
    "\n",
    "print(\"cross references from mondo to other ontologies\")\n",
    "mondo_xrefs = []\n",
    "for x in data: \n",
    "    if x.xrefs:\n",
    "        for xref in x.xrefs: \n",
    "            ont, name = xref.split(':')            \n",
    "            mondo_xrefs.append({'ontology_id':name, 'ontology':ont, 'mondo_id':x.item_id})           \n",
    "mondo_xrefs = pd.DataFrame(mondo_xrefs).drop_duplicates()\n",
    "print('references to the following ontologies are available:')\n",
    "print(np.unique(mondo_xrefs.get('ontology').values))\n",
    "print('references from mondo to mondo indicate equivalence/synonyms')\n",
    "\n",
    "print(\"groupings of mondo terms\")\n",
    "mondo_subsets = []\n",
    "for x in data: \n",
    "    if x.subsets: \n",
    "        for sub in x.subsets: \n",
    "            mondo_subsets.append({'id':x.item_id, 'subset':sub})           \n",
    "mondo_subsets = pd.DataFrame(mondo_subsets).drop_duplicates()\n",
    "print('available subsets by count:')\n",
    "mondo_subsets.groupby('subset').count().sort_values('id',ascending=False)\n",
    "\n",
    "mondo_def = mondo_terms.get(['id','name','definition']).fillna('').copy()\n",
    "for x in mondo_def.itertuples(): \n",
    "    if x.definition:\n",
    "        mondo_def.loc[x.Index, 'definition'] =  x.definition.split('\\\"')[1]\n",
    "    else: \n",
    "        mondo_def.loc[x.Index, 'definition'] = float('nan')\n",
    "mondo_def = mondo_def.dropna()\n",
    "mondo_terms = mondo_terms.drop('definition', axis=1)\n",
    "\n",
    "mondo_terms.to_csv('mondo_terms.csv', index=False)\n",
    "mondo_parents.to_csv('mondo_parents.csv', index=False)\n",
    "mondo_xrefs.to_csv('mondo_references.csv', index=False)\n",
    "mondo_subsets.to_csv('mondo_subsets.csv', index=False)\n",
    "mondo_def.to_csv('mondo_definitions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "with open('./MRCONSO.RRF', 'r') as f: \n",
    "    data = f.readlines()\n",
    "data = [x.split('|') for x in data]\n",
    "\n",
    "columns = ['cui', 'language', 'term_status', 'lui', 'string type', 'string_identifier', 'is_preferred',\n",
    "          'aui', 'source_aui', 'source_cui', 'source_descriptor_dui', 'source', \n",
    "          'source_term_type', 'source_code', 'source_name', 'x', 'x', 'x', 'x']\n",
    "\n",
    "df_umls = pd.DataFrame(data, columns = columns)\n",
    "df_umls = df_umls.query('language==\"ENG\"')\n",
    "df_umls.head()\n",
    "\n",
    "df_umls.to_csv('./umls.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017468b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_mondo_terms = pd.read_csv('./mondo_terms.csv').get(['name','id'])\n",
    "df_mondo_xref = pd.read_csv('./mondo_references.csv')\n",
    "df_umls = pd.read_csv('.umls.csv')\n",
    "\n",
    "map_direct = df_mondo_xref.query('ontology==\"UMLS\"').get(['ontology_id','mondo_id']).rename(columns={'ontology_id':'umls_id'})\n",
    "\n",
    "df_umls_join = df_umls.get(['cui','source_cui', 'source_descriptor_dui', 'source', 'source_code']).drop_duplicates()\n",
    "\n",
    "map1 = pd.merge(df_umls_join, df_mondo_xref, 'inner', left_on='source_cui', right_on='ontology_id')\n",
    "map2 = pd.merge(df_umls_join, df_mondo_xref, 'inner', left_on='source_descriptor_dui', right_on='ontology_id')\n",
    "map3 = pd.merge(df_umls_join, df_mondo_xref, 'inner', left_on='source_code', right_on='ontology_id')\n",
    "\n",
    "map_all = pd.concat([map1, map2, map3]).drop_duplicates()\n",
    "\n",
    "valid = []\n",
    "pairs = [('OMIM','OMIM'),\n",
    "         #('OMIM','OMIMPS'),\n",
    "         #('NCI_NICHD','NCIT'),\n",
    "         #('NCI_FDA','NCIT'),\n",
    "         #('NCI_CTRP','NCIT'),\n",
    "         ('NCI','NCIT'),\n",
    "         #('MTHICD9','ICD9'),\n",
    "         ('MSH','MESH'),\n",
    "         ('MDR','MedDRA'),\n",
    "         #('ICD10CM','ICD10'),\n",
    "         ('ICD10','ICD10'),\n",
    "         ('SNOMEDCT_US','SCTID')]\n",
    "\n",
    "for s,o in pairs: \n",
    "    valid.append(map_all.query('source==@s and ontology==@o'))\n",
    "    \n",
    "map_indirect = pd.concat(valid).rename(columns={'cui':'umls_id'})\n",
    "\n",
    "\n",
    "df_umls_mondo = pd.concat([map_direct, map_indirect.get(['umls_id', 'mondo_id'])]).drop_duplicates()\n",
    "print(df_umls_mondo.head(1))\n",
    "print(df_umls_mondo.shape)\n",
    "\n",
    "\n",
    "df_umls_mondo.to_csv('./umls_mondo.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c48504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import logging\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = 'disease_web_scrape'\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': 'INFO',\n",
    "        'RETRY_TIMES': '100'\n",
    "    }\n",
    "    start_urls = [\n",
    "        'https://www.orpha.net/consor/cgi-bin/Disease_Search.php?lng=EN&search=Disease_Search_List'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        base_url = 'https://www.orpha.net/consor/cgi-bin/'\n",
    "        #list = response.xpath('(//h3[text() = \"Alphabetical list\"]/following-sibling::div[1]//li/a)[1]/@href').get()\n",
    "        #list_href = list[0].xpath('./@href').get()\n",
    "        #request = scrapy.Request(urljoin(base_url, list), callback=self.parse_list)\n",
    "        #yield request\n",
    "\n",
    "        for alphabet in response.xpath('//h3[text() = \"Alphabetical list\"]/following-sibling::div[1]//li/a'):\n",
    "            list_href = alphabet.xpath('./@href').get()\n",
    "            request = scrapy.Request(urljoin(base_url, list_href), callback=self.parse_list)\n",
    "            yield request\n",
    "\n",
    "    def parse_list(self, response):\n",
    "        logging.info((\"List: \" + response.request.url))\n",
    "        base_url = 'https://www.orpha.net/consor/cgi-bin/'\n",
    "        for disease in response.xpath('//div[@id = \"result-box\"]/ul/li/a'):\n",
    "            disease_name = disease.xpath('./text()').get()\n",
    "            disease_url = disease.xpath('./@href').get()\n",
    "            request = scrapy.Request(urljoin(base_url, disease_url), callback=self.parse_content, errback=self.errback)\n",
    "            request.meta['disease'] = disease_name\n",
    "            yield request\n",
    "\n",
    "    def parse_content(self, response):\n",
    "        disease_shortname = response.meta['disease']\n",
    "        disease_name = response.xpath(\"//h2[3]/text()\").get()\n",
    "        disease_id = response.xpath(\"//div[@class = 'idcard artBlock']/h3/text()\").get()\n",
    "        definition = response.xpath('//div[@class = \"definition\"]/section/p/text()').get()\n",
    "        prevalence = response.xpath(\"//ul[@class = 'idData']//em[text()='Prevalence: ']/following-sibling::strong/text()\").get()\n",
    "        UMLS = response.xpath(\"//ul[@class = 'idData']//em[text()='UMLS: ']/following-sibling::strong/text()\").get()\n",
    "        epidemiology = response.xpath(\"//div[@class = 'articleInfo']/h3[contains(text(), 'Epidemiology')]/following-sibling::section[1]/p/text()\").get()\n",
    "        clinical_description = response.xpath(\"//div[@class = 'articleInfo']/h3[contains(text(), 'Clinical description')]/following-sibling::section[1]/p/text()\").get()\n",
    "        management_and_treatment = response.xpath(\"//div[@class = 'articleInfo']/h3[contains(text(), 'Management and treatment')]/following-sibling::section[1]/p/text()\").get()\n",
    "        yield{\n",
    "            'disease_shortname': disease_shortname,\n",
    "            'disease_name': disease_name,\n",
    "            'disease_id': disease_id,\n",
    "            'definition': definition,\n",
    "            'prevalence': prevalence,\n",
    "            'UMLS': UMLS,\n",
    "            'epidemiology': epidemiology,\n",
    "            'clinical_description': clinical_description,\n",
    "            'management_and_treatment': management_and_treatment\n",
    "        }\n",
    "\n",
    "    def errback(self, response):\n",
    "        logging.info((\"ERROR: \" + response.meta['disease']))\n",
    "        request = scrapy.Request(response.request.url, callback=self.parse_content, errback=self.errback)\n",
    "        yield request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c32d27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
